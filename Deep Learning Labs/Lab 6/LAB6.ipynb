{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 06 - Generative adversarial networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this laboratory we will implement what is called in the literature a Cycle GAN (https://arxiv.org/pdf/1703.10593.pdf). These are powerful models that can learn to translate images without having paired samples to learn from.\n",
    "\n",
    "A Generative Adversarial Network can generate novel data that is similar to that found in the training set (comes from the same distribution). As you've seen in the lecture, classic models can take random noise as input and learn to generate such data. There are also models where, in addition to the random noise, the model can take another input which it is meant to translate. For instance, this paper https://arxiv.org/pdf/1611.07004.pdf showcases translating images containing outlines alone to fully fledged objects.\n",
    "\n",
    "![](./edge_to_obj_.png)\n",
    "\n",
    "In such cases, there are pairs of desired inputs and outputs. However, it is rarely the case that we can create or benefit from such well structured datasets. The general case consists in samples gathered separately from the two classes that we wish to translate. For instance you can have several images of horses, and several images of zebras with no way of pairing them.\n",
    "\n",
    "![](./h2z.png)\n",
    "\n",
    "A CycleGAN can learn to translate from one class to another given such a scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CycleGAN\n",
    "\n",
    "A CycleGAN primarily consists in have two GAN models: one that translates from the first class to the second, and one that translates from the second class to the first. Lets name those classes X and Y.\n",
    "\n",
    "There will be a generator that takes as input an image from the X class and outputs an image from the Y class, a discrimiator that has to distinguish real Y images from fake ones, a generator that translates from Y to X and a final distriminator that classifies real and fake X images.\n",
    "\n",
    "In order to prevent the generators to output a single image from the opposite class regardless of the input there is an additional factor that the model has to optimize; the most important aspect of the architecture. The translations have to be cycle consistent. This means that if we take an X image and translate it into a Y image, and then translate it again into an X image, we should end up with the exact same image we started with. This is the fundamental ideea of this model.\n",
    "\n",
    "![](./cycle.png)\n",
    "\n",
    "Additionally, we will introduce another loss term. Given a X image, we what that the generator that translates from Y to X to exactly reproduce it (identity loss), similarly, the other way around."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implemenatation\n",
    "\n",
    "With the help of your superviser you can implement a CycleGAN starting from this code skeleton. The example featured will be translating apples to oranges, this is so that a model trained for a few iterations can provide visually interesting results. The same model cand then be applied to the zebras to horses dataset, provided you train the model for a larger number of iterations, all you have to do is replace the 'apple2orange' dataset name to 'horse2zebra'. The script will load that dataset and train the model on it without any other changes required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, importing all neccessary tools and loading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow_examples.models.pix2pix import pix2pix\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import time\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to loading the dataset, we will also jitter and normalize the input in order to enhance our models performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jitter(im, label):\n",
    "    im = tf.image.resize(im, [286, 286])\n",
    "    im = tf.image.random_crop(im, [256, 256, 3])\n",
    "    # im = tf.image.resize(im, [128, 128])\n",
    "    im = tf.image.random_flip_left_right(im)\n",
    "\n",
    "    return im, label\n",
    "\n",
    "def normalize(im, label):\n",
    "    # im = tf.image.resize(im, [128, 128])\n",
    "    return tf.cast(im, tf.float32) / 255.\n",
    "\n",
    "dataset, metadata = tfds.load(\n",
    "    'cycle_gan/apple2orange',\n",
    "    with_info = True, as_supervised = True\n",
    ")\n",
    "train_x = dataset['trainA'].map(jitter).map(normalize).repeat().shuffle(1000).batch(10)\n",
    "train_y = dataset['trainB'].map(jitter).map(normalize).repeat().shuffle(1000).batch(10)\n",
    "test_x = dataset['testA'].map(normalize).batch(10)\n",
    "test_y = dataset['testB'].map(normalize).batch(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will define our generator architecture. For this class we will use a simple U-Net generator. The ideea is to concatenate the convolutional features in the following manner.\n",
    "\n",
    "![](./unet.jpg)\n",
    "\n",
    "For instance, if your first layer has 32 filters, your last layer (excluding the final output) that will also have 32 layers, will be contatenated with the first one obtaining 64 channels as input for what follows. Another example suppose you have an architecture with the following number of filters: input -> 32 -> 64 -> 128 -> 64 -> 32 -> 3(final output). Then, the final 32-filter convolution output will have its output concatened with the output of the first 32-filter convolution, and the last 64-filter convolution will have its output concatenated with that of the first 64-filter convolution output. The reason for this is that the generators have to reconstruct pretty much the same visual structure they received as input so instead of having the task of memorizing the structure, we will simply give the the structure for it as it advances in its reconstruction.\n",
    "\n",
    "Our final layer will have sigmoid activation in order to reconstruct the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.downscale_layers = [layers.Conv2D(64, 3, padding='same', input_shape=(256, 256, 3), activation='relu')]\n",
    "        # define a list of convolutional layers with\n",
    "        # 64, 128, 256 and 512 filters respectively\n",
    "        # relu activations, same padding and a kernel of size 3\n",
    "        filters = [128, 256, 512]\n",
    "        for f in filters:\n",
    "            self.downscale_layers.append(layers.Conv2D(f, 3, padding='same', activation='relu'))\n",
    "\n",
    "            # define a 2x2 max pooling layer\n",
    "        self.pool_layer = layers.MaxPool2D((2, 2))\n",
    "\n",
    "        # define a list of transposed convolutions with\n",
    "        # 256, 128 and 64 filters respectively\n",
    "        # relu activations, same padding, a kernnel of size 3 and a stride of size 2\n",
    "        transposed_filters = [256, 128, 64]\n",
    "        self.transposed_convs = []\n",
    "        for t_f in transposed_filters:\n",
    "            self.transposed_convs.append(layers.Conv2DTranspose(t_f, 3,strides=(2, 2), padding='same', activation='relu'))\n",
    "\n",
    "        # define a final deconvolution with 3 filters, kernel size 3, stride 2,\n",
    "        # sigmoid activation, and same padding\n",
    "        self.final_layer = layers.Conv2DTranspose(3, 3, strides=(2, 2), padding='same', activation='sigmoid')\n",
    "\n",
    "\n",
    "    def call(self, input):\n",
    "        # sequentially apply the convolutions and pooling layer\n",
    "        # retain all max pooling outputs in a list\n",
    "        intermed_results = []\n",
    "        for layer in self.downscale_layers:\n",
    "            input = layer(input)\n",
    "            input = self.pool_layer(input)\n",
    "            intermed_results.append(input)\n",
    "        # sequentially apply all deconvolutions (except for the output layer)\n",
    "        # concatenate each output with its correspoding convolutional output\n",
    "        for i, tr_layer in enumerate(self.transposed_convs):\n",
    "            output = tr_layer(input)\n",
    "            input = tf.concat([output, intermed_results[-(i+2)]], axis=-1)\n",
    "\n",
    "            #apply the final decovolution and return the output\n",
    "        output = self.final_layer(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the discrminator, since its will not have a complicated architecture, it will suffice to define a function that returns a sequential layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_discriminator():\n",
    "    # return a sequential model with\n",
    "    # 4 convolutions with max pooling with the same parameters as the ones in the generator\n",
    "    # a dense layer with 128 units and relu activation\n",
    "    # a final prediction fully connected layer with 1 unit and sigmoid activation\n",
    "    return tf.keras.Sequential([\n",
    "        layers.Conv2D(64, 3, padding='same', input_shape=(256, 256, 3), activation='relu'),\n",
    "        layers.MaxPool2D((2, 2)),\n",
    "        layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "        layers.MaxPool2D((2, 2)),\n",
    "        layers.Conv2D(256, 3, padding='same',  activation='relu'),\n",
    "        layers.MaxPool2D((2, 2)),\n",
    "        layers.Conv2D(512, 3, padding='same',  activation='relu'),\n",
    "        layers.MaxPool2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will instantiate all models and define their individual optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_x_y = Generator()\n",
    "gen_y_x = Generator()\n",
    "disc_x = new_discriminator()\n",
    "disc_y = new_discriminator()\n",
    "\n",
    "opt_gen_x_y = tf.keras.optimizers.Adam(2e-4, beta_1 = 0.5)\n",
    "opt_gen_y_x = tf.keras.optimizers.Adam(2e-4, beta_1 = 0.5)\n",
    "opt_disc_x = tf.keras.optimizers.Adam(2e-4, beta_1 = 0.5)\n",
    "opt_disc_y = tf.keras.optimizers.Adam(2e-4, beta_1 = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complex part comes next, defining the fit_iteration function. If you think it thoroughly, take it step by step and work with your supervisor, it should come naturally. As a special mention, whenever using gradient taping you should perform **all** (loss) computations within the context. Outside the context should only be gradient applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "def discriminator_loss(real, generated):\n",
    "  real_loss = binary_cross_entropy(tf.ones_like(real), real)\n",
    "\n",
    "  generated_loss = binary_cross_entropy(tf.zeros_like(generated), generated)\n",
    "\n",
    "  total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "  return total_disc_loss * 0.5\n",
    "\n",
    "def generator_loss(generated):\n",
    "  return binary_cross_entropy(tf.ones_like(generated), generated)\n",
    "\n",
    "def calc_cycle_loss(real_image, cycled_image):\n",
    "  loss1 = tf.reduce_mean(tf.reduce_sum(tf.abs(real_image - cycled_image), axis=(1,2,3)))\n",
    "\n",
    "  return 10 * loss1\n",
    "\n",
    "def identity_loss(real_image, same_image):\n",
    "  loss = tf.reduce_mean(tf.reduce_sum(tf.abs(real_image - same_image), axis=(1,2,3)))\n",
    "  return 10 * 0.5 * loss\n",
    "\n",
    "@tf.function\n",
    "def fit_iteration(real_x, real_y):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # watch variables from all 4 models\n",
    "        tape.watch(gen_x_y.trainable_variables)\n",
    "        tape.watch(gen_y_x.trainable_variables)\n",
    "        tape.watch(disc_x.trainable_variables)\n",
    "        tape.watch(disc_y.trainable_variables)\n",
    "\n",
    "        # compute all need model outputs\n",
    "\n",
    "        # generators applied on the real images\n",
    "        fake_y = gen_x_y(real_x)\n",
    "        fake_x = gen_y_x(real_y)\n",
    "        # generators applied on the fake images (cycling)\n",
    "        cycle_x = gen_y_x(fake_y)\n",
    "        cycle_y = gen_x_y(fake_x)\n",
    "        # generators applied for reconstructions (i.e. gen_x_y(real_y)) for the identity loss\n",
    "        same_y = gen_x_y(real_y)\n",
    "        same_x = gen_y_x(real_x)\n",
    "        # discriminators applied on fake and real images\n",
    "        disc_real_x = disc_x(real_x)\n",
    "        disc_real_y = disc_y(real_y)\n",
    "\n",
    "        disc_fake_x = disc_x(fake_x)\n",
    "        disc_fake_y = disc_y(fake_y)\n",
    "\n",
    "        # compute discriminator losses. Use mean binary cross entropy\n",
    "        disc_x_loss = discriminator_loss(disc_real_x, disc_fake_x)\n",
    "        disc_y_loss = discriminator_loss(disc_real_y, disc_fake_y)\n",
    "\n",
    "        # compute generator losses. Use mean binary_cross_entropy\n",
    "        gen_x_y_loss = generator_loss(disc_fake_y)\n",
    "        gen_y_x_loss = generator_loss(disc_fake_x)\n",
    "        # remember that the generator should trick the distriminator into thinking that the fake samples are real\n",
    "        # should be cycle consistent\n",
    "        # and should reproduce the input image if it is from the class that it should generate\n",
    "        total_cycle_loss = calc_cycle_loss(real_x, cycle_x) + calc_cycle_loss(real_y, cycle_y)\n",
    "        total_loss_gen_x_y = gen_x_y_loss + total_cycle_loss + identity_loss(real_x, same_x)\n",
    "        total_loss_gen_y_x = gen_y_x_loss + total_cycle_loss + identity_loss(real_y, same_y)\n",
    "\n",
    "        # compute and apply all gradients\n",
    "    gen_x_y_gradients = tape.gradient(total_loss_gen_x_y, gen_x_y.trainable_variables)\n",
    "    gen_y_x_gradients = tape.gradient(total_loss_gen_y_x, gen_y_x.trainable_variables)\n",
    "\n",
    "    disc_y_gradients = tape.gradient(disc_y_loss, disc_y.trainable_variables)\n",
    "    disc_x_gradients = tape.gradient(disc_x_loss, disc_x.trainable_variables)\n",
    "\n",
    "    opt_gen_x_y.apply_gradients(zip(gen_x_y_gradients, gen_x_y.trainable_variables))\n",
    "    opt_gen_y_x.apply_gradients(zip(gen_y_x_gradients, gen_y_x.trainable_variables))\n",
    "\n",
    "    opt_disc_x.apply_gradients(zip(disc_x_gradients, disc_x.trainable_variables))\n",
    "    opt_disc_y.apply_gradients(zip(disc_y_gradients, disc_y.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the implementation is standard, trains the model for a few iterations and plots a few transformations applied on test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(\n",
    "            gen_x_y=gen_x_y,\n",
    "            gen_y_x=gen_y_x,\n",
    "            disc_x=disc_x,\n",
    "            disc_y=disc_y)\n",
    "ckpt_manager = tf.train.CheckpointManager(\n",
    "            ckpt,\n",
    "            checkpoint_path,\n",
    "            max_to_keep=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Graph execution error:\n\nDetected at node 'generator_1/conv2d_transpose_4/conv2d_transpose' defined at (most recent call last):\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 390, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Ahmad Wali\\AppData\\Local\\Temp\\ipykernel_19648\\3080217372.py\", line 5, in <module>\n      fit_iteration(\n    File \"C:\\Users\\Ahmad Wali\\AppData\\Local\\Temp\\ipykernel_19648\\2392216702.py\", line 37, in fit_iteration\n      fake_x = gen_y_x(real_y)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ahmad Wali\\AppData\\Local\\Temp\\ipykernel_19648\\2407267538.py\", line 38, in call\n      for i, tr_layer in enumerate(self.transposed_convs):\n    File \"C:\\Users\\Ahmad Wali\\AppData\\Local\\Temp\\ipykernel_19648\\2407267538.py\", line 39, in call\n      output = tr_layer(input)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\keras\\layers\\convolutional\\conv2d_transpose.py\", line 296, in call\n      outputs = backend.conv2d_transpose(\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\keras\\backend.py\", line 6119, in conv2d_transpose\n      x = tf.compat.v1.nn.conv2d_transpose(\nNode: 'generator_1/conv2d_transpose_4/conv2d_transpose'\nNo algorithm worked!  Error messages:\n  Profiling failure on CUDNN engine 1#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n  Profiling failure on CUDNN engine 1: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n  Profiling failure on CUDNN engine 3#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2390794256 bytes.\n  Profiling failure on CUDNN engine 3: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2390794256 bytes.\n  Profiling failure on CUDNN engine 0#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n  Profiling failure on CUDNN engine 0: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n\t [[{{node generator_1/conv2d_transpose_4/conv2d_transpose}}]] [Op:__inference_fit_iteration_7806]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19648\\438019247.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mn_iterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     fit_iteration(\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     )\n",
      "\u001b[1;32mc:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Graph execution error:\n\nDetected at node 'generator_1/conv2d_transpose_4/conv2d_transpose' defined at (most recent call last):\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 390, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Ahmad Wali\\AppData\\Local\\Temp\\ipykernel_19648\\3080217372.py\", line 5, in <module>\n      fit_iteration(\n    File \"C:\\Users\\Ahmad Wali\\AppData\\Local\\Temp\\ipykernel_19648\\2392216702.py\", line 37, in fit_iteration\n      fake_x = gen_y_x(real_y)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ahmad Wali\\AppData\\Local\\Temp\\ipykernel_19648\\2407267538.py\", line 38, in call\n      for i, tr_layer in enumerate(self.transposed_convs):\n    File \"C:\\Users\\Ahmad Wali\\AppData\\Local\\Temp\\ipykernel_19648\\2407267538.py\", line 39, in call\n      output = tr_layer(input)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\keras\\layers\\convolutional\\conv2d_transpose.py\", line 296, in call\n      outputs = backend.conv2d_transpose(\n    File \"c:\\Users\\Ahmad Wali\\anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\keras\\backend.py\", line 6119, in conv2d_transpose\n      x = tf.compat.v1.nn.conv2d_transpose(\nNode: 'generator_1/conv2d_transpose_4/conv2d_transpose'\nNo algorithm worked!  Error messages:\n  Profiling failure on CUDNN engine 1#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n  Profiling failure on CUDNN engine 1: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n  Profiling failure on CUDNN engine 3#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2390794256 bytes.\n  Profiling failure on CUDNN engine 3: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2390794256 bytes.\n  Profiling failure on CUDNN engine 0#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n  Profiling failure on CUDNN engine 0: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n\t [[{{node generator_1/conv2d_transpose_4/conv2d_transpose}}]] [Op:__inference_fit_iteration_7806]"
     ]
    }
   ],
   "source": [
    "train_x = iter(train_x)\n",
    "train_y = iter(train_y)\n",
    "n_iterations = 500\n",
    "for i in range(n_iterations):\n",
    "    fit_iteration(\n",
    "        next(train_x), next(train_y)\n",
    "    )\n",
    "    print(i / n_iterations, end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, you can implement Instance Normalization (https://arxiv.org/pdf/1607.08022.pdf) and regularization techniques in your model in order to further enhance performances.\n",
    "\n",
    "Even without those, provided the implementation has been successful, the following block should yield semi-realistc images, even after training for as few as 500 iterations with a batch size of 1. Try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = iter(test_x)\n",
    "test_y = iter(test_y)\n",
    "import matplotlib.pyplot as plt\n",
    "for _ in range(6):\n",
    "    real_x, real_y = next(test_x), next(test_y)\n",
    "    plt.imshow(\n",
    "        np.concatenate([\n",
    "            real_x, gen_x_y(real_x)\n",
    "        ], axis = 2)[0]\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep_Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4be34ee29682d8153bb33aa0ed218e251bc723c8d0fb2453deb0a4cf51f72620"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
